@Library('shared')

def runOn(environment, body) {
    if (params.EXECUTION_ENVIRONMENT != environment) {
        return
    }
    body.call()
}

def globalExecutor(body) {
    runOn("kubernetes") {
        podTemplate {
            node(POD_LABEL) {
                ansiColor('xterm') {
                    body.call()
                }
            }
        }
    }
    node {
        runOn("docker") {
            docker.image("docker.io/venthe/ubuntu-runner:22.10").inside("--entrypoint=''") {
                ansiColor('xterm') {
                    body.call()
                }
            }
        }
    }
}

def runner(image, body) {
    runOn("kubernetes") {
        podTemplate(yaml: """\
                    kind: Pod
                    spec:
                      containers:
                        - name: runner
                          image: ${image}
                          imagePullPolicy: Always
                          securityContext:
                            privileged: true
                          command:
                            - sleep
                          args:
                            - 9999999""".stripMargin().stripIndent()) {
            node(POD_LABEL) {
                container("runner") {
                    ansiColor('xterm') {
                        body.call()
                    }
                }
            }
        }
    }
    runOn("docker") {
        def volumes = ""
        docker.image(image).inside("""--entrypoint='' --interactive --tty ${volumes}""") {
            ansiColor('xterm') {
                body.call()
            }
        }
    }
}

def runOnNode() {
    sh 'NODE_OPTIONS=--enable-source-maps node /runner/index.js'
}

static def normalizeEventName(str) {
    return str.replace("-", "").toLowerCase()
}

static def handles(events, input) {
    if (events == null) {
        return false
    }

    println "handles " + events.inspect()

    return events
            .collect { normalizeEventName(it) }
            .contains(normalizeEventName(input["type"]))
}

def prepareEnvFile(workflowFile, jobName) {
    // FIXME: Rewrite as withEnv
    //  With env is not working on docker node?
    writeFile file: "ci.env", text: [
            "VPIPELINE_BUILD_ID"   : "${env.BUILD_ID}",
            "VPIPELINE_GERRIT_URL" : "${params.GERRIT_URL}",
            "VPIPELINE_JOB_NAME"   : "${jobName}",
            "VPIPELINE_NEXUS_URL"  : "http://nexus-nexus-repository-manager.infrastructure",
            "VPIPELINE_SECRET_NAME": "infrastructure",
            "VPIPELINE_VAULT_URL"  : "http://vault.infrastructure:8200/v1",
            "VPIPELINE_DOCKER_URL" : "https://docker.home.arpa",
            "VPIPELINE_WORKFLOW"   : "${workflowFile}",
            "GIT_SSH_COMMAND"      : "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no"
    ].collect { "${it.key}=${it.value}" }
            .join('\n')
    sh "mv ci.env /runner/metadata/env"
}

def prepareWorkflow(workflowFile, input) {
    try {
        println "Loading workflow: ${workflowFile.toString()}"
        def file = readFile workflowFile.toString()
        def workflow = shared.parseYaml(file)
        if (workflow == null) {
            throw new Exception("Workflow should not be null")
        }

        def workflowName = workflow['name'] ? "${workflow['name']} - ${workflowFile.name}" : workflowFile.name
        def on = workflow['on']

        if (on == null) {
            println "We are not handling this due to lack of ON"
            throw new Exception("There is no \"on\" property, this workflow will never run")
        }
        if (Map.isAssignableFrom(on.getClass())) {
            def events = on['event']
            if (events != null) {
                println "We are handling a map" + on.inspect()

                if (Collection.isAssignableFrom(events.getClass())) {
                    if (!handles(events, input)) {
                        print "Event ${input['type']} not handled in ${workflow['on']}"
                        return
                    }
                } else {
                    if (!handles([events], input)) {
                        print "Event ${input['type']} not handled in ${workflow['on']}"
                        return
                    }
                }
            } else {
                throw new Exception("Should not happen, as we always should handle those events" + on.inspect())
            }

        } else if (Collection.isAssignableFrom(on.getClass())) {
            println "We are handling a list" + workflow['on'].inspect()
            if (!handles(workflow['on'], input)) {
                print "Event ${input['type']} not handled in ${workflow['on']}"
                return
            }
        } else {
            throw new Exception("2 On unrecognized. Should not happen ${on.getClass()} ${on.getClass() instanceof LinkedHashMap}")
        }

        def action = {
            workflow['jobs'].each { jobName, job ->
                runner(job['runs-on']) {
                    cleanWs()
                    unstash 'INPUT'
                    prepareEnvFile(workflowFile.toString(), jobName)
                    withCredentials(bindings: [sshUserPrivateKey(credentialsId: 'gerrit',                    \
                                                                        keyFileVariable: 'SSH_KEY_FOR_ABC',                    \
                                                                        passphraseVariable: '',                    \
                                                                        usernameVariable: '')]) {
                        sh "mkdir -p /root/.ssh && cp ${SSH_KEY_FOR_ABC} /root/.ssh/id_rsa"
                    }
                    sh "chmod u=rwx,g=,o= ~/.ssh/*"
                    sh "mv INPUT /runner/metadata/event.json"
                    stage("[${workflow['name']}/${jobName}]") {
                        runOnNode()
                    }
                }
            }
        }
        return ["${workflowName}": action]
    } catch (Exception e) {
        return ["${workflowFile.toString()}": {
            stage("${workflowFile.toString()}") {
                error("File content:\n${readFile(workflowFile.toString())}\n\n${e.getMessage()}\n${printStackTrace(e)}")
            }
        }]
    }
}

// FIXME: Rewrite as standard Jenkins log
//  to have a stack pretty printed, we use our own stack trace prettifier
def printStackTrace(exception) {
    StringWriter writer = new StringWriter();
    PrintWriter printWriter = new PrintWriter(writer);
    exception.printStackTrace(printWriter);
    printWriter.flush();

    return writer.toString();
}

def checkoutProperties(project1, branch1, ref1) {
    return [$class           : 'GitSCM',
            branches         : [
                    [name: "${ref1}"]
            ],
            extensions       : [
                    [$class: 'LocalBranch', localBranch: "**"],
                    [$class: 'BuildSingleRevisionOnly'],
                    [$class: 'CloneOption', shallow: true, honorRefspec: true],
                    [$class: 'SparseCheckoutPaths', sparseCheckoutPaths: [
                            [$class: 'SparseCheckoutPath', path: '.pipeline/']
                    ]]
            ],
            userRemoteConfigs: [
                    [credentialsId: 'gerrit',
                     refspec      : "+${branch1}:refs/remotes/origin/${branch1} +${ref1}:refs/remotes/origin/${ref1}",
                     url          : "${params.GERRIT_URL}/${"${project1}"}"
                    ]
            ]
    ]
}

properties([parameters([
        string(name: 'EXECUTION_ENVIRONMENT', defaultValue: 'kubernetes', description: ''),
        stashedFile(name: 'INPUT', default: null, description: ''),
        // text(name: 'INPUT_TEST', default: null, description: ''),
        string(name: 'GERRIT_URL', defaultValue: '{{ gerrit.sshUrl }}'),
])])

if (params.SEED_JOB != null) {
    currentBuild.result = 'ABORTED'
    currentBuild.displayName = "#${BUILD_NUMBER} Aborted: Seeding job used to register actual parameters"
    error('Stopping earlyâ€¦')
}

globalExecutor {
    def input
    stage("Load input") {
        cleanWs()
        unstash 'INPUT'
        input = readJSON file: "INPUT"
    }
    def workflows
    stage("Prepare workflows") {
        println "Checking out actions"
        def branch1 = "${input['change']['branch']}"
        def ref1 = "${input['patchSet']['ref']}"
        def project1 = "${input['change']['project']}"
        def type1 = "${input['type']}"
        currentBuild.displayName = "#${BUILD_NUMBER} [${project1}] ${type1}: +${branch1}:${ref1}"
        currentBuild.description = "The best description."

        checkout(checkoutProperties(project1, branch1, ref1))
        workflows = findFiles(glob: '.pipeline/workflows/*.y*ml')
                .collect { prepareWorkflow(it, input) }
                .findAll { it != null }
                .collectEntries { it }
        workflows.failFast = false
    }
    stage("Run jobs") {
        parallel workflows
    }
}
